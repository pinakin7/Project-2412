{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ImmyKcwQPvJB",
    "outputId": "afe0e42e-4f47-4c68-dcef-f6e98146c1b8",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:33.582900100Z",
     "start_time": "2023-12-09T22:24:30.803775100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1b044d0cc70>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:33.672157200Z",
     "start_time": "2023-12-09T22:24:33.582900100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Version: 3.10.11\n",
      "torch Version: 2.1.1+cu118\n",
      "torchvision Version: 0.16.1+cu118\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"python Version: {sys.version.split(' ')[0]}\")\n",
    "print(f\"torch Version: {torch.__version__}\")\n",
    "print(f\"torchvision Version: {torchvision.__version__}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nitbSS77Px4X",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:33.672157200Z",
     "start_time": "2023-12-09T22:24:33.629898900Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparameter:\n",
    "    num_classes: int        = 10\n",
    "    batchsize: int          = 128\n",
    "    num_epochs: int         = 50\n",
    "    latent_size: int        = 32\n",
    "    n_critic: int           = 5\n",
    "    critic_size: int        = 1024\n",
    "    generator_size: int     = 1024\n",
    "    critic_hidden_size: int = 1024\n",
    "    gp_lambda: float        = 10.0\n",
    "    sigma: float            = 1.1\n",
    "    weight_clip : float     = 2.5\n",
    "hp = Hyperparameter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "u05eDLLwbYAo",
    "outputId": "20775a1f-2619-42b8-e5e0-7dfba19e4f0f",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:33.673160900Z",
     "start_time": "2023-12-09T22:24:33.645440700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_embedding = nn.Sequential(\n",
    "            nn.Linear(hp.latent_size, hp.generator_size // 2),\n",
    "        )\n",
    "        self.condition_embedding = nn.Sequential(\n",
    "            nn.Linear(hp.num_classes, hp.generator_size // 2),\n",
    "        )\n",
    "        self.tcnn = nn.Sequential(\n",
    "        nn.ConvTranspose2d( hp.generator_size, hp.generator_size, 4, 1, 0),\n",
    "        nn.BatchNorm2d(hp.generator_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d( hp.generator_size, hp.generator_size // 2, 3, 2, 1),\n",
    "        nn.BatchNorm2d(hp.generator_size // 2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d( hp.generator_size // 2, hp.generator_size // 4, 4, 2, 1),\n",
    "        nn.BatchNorm2d(hp.generator_size // 4),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d( hp.generator_size // 4, 1, 4, 2, 1),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, latent, condition):\n",
    "        vec_latent = self.latent_embedding(latent)\n",
    "        vec_class = self.condition_embedding(condition)\n",
    "        combined = torch.cat([vec_latent, vec_class], dim=1).reshape(-1, hp.generator_size, 1, 1)\n",
    "        return self.tcnn(combined)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.condition_embedding = nn.Sequential(\n",
    "            nn.Linear(hp.num_classes, hp.critic_size * 4),\n",
    "        )\n",
    "        self.cnn_net = nn.Sequential(\n",
    "        nn.Conv2d(1, hp.critic_size // 4, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size // 4, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(hp.critic_size // 4, hp.critic_size // 2, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size // 2, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),   \n",
    "        nn.Conv2d(hp.critic_size // 2, hp.critic_size, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Flatten(),\n",
    "        )\n",
    "        self.Critic_net = nn.Sequential(\n",
    "        nn.Linear(hp.critic_size * 8, hp.critic_hidden_size),\n",
    "        nn.LeakyReLU(0.2, inplace=True),   \n",
    "        nn.Linear(hp.critic_hidden_size, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, condition):\n",
    "        vec_condition = self.condition_embedding(condition)\n",
    "        cnn_features = self.cnn_net(image)\n",
    "        combined = torch.cat([cnn_features, vec_condition], dim=1)\n",
    "        return self.Critic_net(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGaEIpNJbHEJ",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:34.084018600Z",
     "start_time": "2023-12-09T22:24:33.662642500Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "                                \n",
    "dataset  = torchvision.datasets.MNIST(\"mnist\", download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=hp.batchsize, num_workers=1,\n",
    "                                         shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "critic, generator = Critic().to(\"cuda\"), Generator().to(\"cuda\")\n",
    "\n",
    "critic_optimizer = optim.SGD(critic.parameters(), lr=1e-4,momentum=0.9)\n",
    "generator_optimizer = optim.AdamW(generator.parameters(), lr=5e-5,betas=(0., 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "__main__.Critic"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(critic)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:24:38.087150700Z",
     "start_time": "2023-12-09T22:24:38.071636400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for parameter in critic.parameters():\n",
    "    parameter.register_hook(\n",
    "        lambda grad: grad + (1/hp.batchsize)*hp.sigma * torch.randn(parameter.shape).cuda()\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:58:43.954758300Z",
     "start_time": "2023-12-09T21:58:43.941199300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpinakin7\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\pinak/.netrc\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mpinakin7\u001B[0m (\u001B[33m2412\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>A:\\Project\\2412\\wandb\\run-20231209_165846-wduoiakh</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/2412/2412%20DP%20GAN%20Model/runs/wduoiakh' target=\"_blank\">volcanic-oath-5</a></strong> to <a href='https://wandb.ai/2412/2412%20DP%20GAN%20Model' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/2412/2412%20DP%20GAN%20Model' target=\"_blank\">https://wandb.ai/2412/2412%20DP%20GAN%20Model</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/2412/2412%20DP%20GAN%20Model/runs/wduoiakh' target=\"_blank\">https://wandb.ai/2412/2412%20DP%20GAN%20Model/runs/wduoiakh</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "wandb.login(key=\"c8b7ef31a46dca526003891b3b6dda9f2a6391cf\")\n",
    "\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"2412 DP GAN Model\",\n",
    "    entity=\"2412\",\n",
    "    config={\n",
    "        \"architecture\": \"DP WGAN\",\n",
    "        \"dataset\": \"MNIST\",\n",
    "        \"optimizer\": \"SGD\",\n",
    "        \"loss function\": \"Wasserstien Distance\",\n",
    "        \"epochs\": hp.num_epochs,\n",
    "        \"epsilon\" : 10\n",
    "    },\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T21:58:46.748622400Z",
     "start_time": "2023-12-09T21:58:43.955759600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AKkYiOC2P9mi",
    "outputId": "238aca44-9928-40df-f20f-45615efe7853",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:06:54.064224500Z",
     "start_time": "2023-12-09T21:58:46.754620700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0/50][      0][    2.74s]\td_loss/g_loss:  3.2/-0.05\t\n",
      "[ 0/50][    100][   17.60s]\td_loss/g_loss: -4.0/ 1.4\t\n",
      "[ 0/50][    200][   32.37s]\td_loss/g_loss: -4.2/-0.47\t\n",
      "[ 0/50][    300][   47.26s]\td_loss/g_loss: -5.5/0.31\t\n",
      "[ 0/50][    400][   62.20s]\td_loss/g_loss: -8.0/-0.87\t\n",
      "[ 1/50][    468][   75.03s]\td_loss/g_loss: -6.1/-1.8\t\n",
      "[ 1/50][    568][   89.98s]\td_loss/g_loss: -5.8/-0.82\t\n",
      "[ 1/50][    668][  104.92s]\td_loss/g_loss: -2.0/-1.3\t\n",
      "[ 1/50][    768][  119.82s]\td_loss/g_loss: -4.0/0.19\t\n",
      "[ 1/50][    868][  134.70s]\td_loss/g_loss: -0.34/-4.5\t\n",
      "[ 2/50][    936][  147.34s]\td_loss/g_loss: -1.2/-6.2\t\n",
      "[ 2/50][   1036][  162.25s]\td_loss/g_loss: -1.3/-3.2\t\n",
      "[ 2/50][   1136][  177.12s]\td_loss/g_loss: -1.4/-5.2\t\n",
      "[ 2/50][   1236][  192.00s]\td_loss/g_loss: -0.93/-4.1\t\n",
      "[ 2/50][   1336][  206.87s]\td_loss/g_loss: -0.5/-3.2\t\n",
      "[ 3/50][   1404][  219.51s]\td_loss/g_loss: -1.3/-5.6\t\n",
      "[ 3/50][   1504][  234.47s]\td_loss/g_loss: -2.4/-3.5\t\n",
      "[ 3/50][   1604][  249.39s]\td_loss/g_loss: -0.65/-5.3\t\n",
      "[ 3/50][   1704][  264.32s]\td_loss/g_loss: -0.34/-3.1\t\n",
      "[ 3/50][   1804][  279.27s]\td_loss/g_loss: -0.59/-1.5\t\n",
      "[ 4/50][   1872][  292.03s]\td_loss/g_loss: -0.25/-4.6\t\n",
      "[ 4/50][   1972][  306.95s]\td_loss/g_loss: -0.13/-3.9\t\n",
      "[ 4/50][   2072][  321.94s]\td_loss/g_loss: -0.61/-3.7\t\n",
      "[ 4/50][   2172][  336.89s]\td_loss/g_loss: -0.91/-3.3\t\n",
      "[ 4/50][   2272][  351.82s]\td_loss/g_loss: 0.21/-0.048\t\n",
      "[ 5/50][   2340][  364.61s]\td_loss/g_loss: -0.23/-2.0\t\n",
      "[ 5/50][   2440][  379.53s]\td_loss/g_loss: 0.66/-1.3\t\n",
      "[ 5/50][   2540][  394.53s]\td_loss/g_loss: -0.51/-0.9\t\n",
      "[ 5/50][   2640][  409.47s]\td_loss/g_loss: 0.64/-1.6\t\n",
      "[ 5/50][   2740][  424.41s]\td_loss/g_loss: 0.27/-5.7\t\n",
      "[ 6/50][   2808][  437.10s]\td_loss/g_loss:  1.7/-7.5\t\n",
      "[ 6/50][   2908][  452.06s]\td_loss/g_loss: -0.64/-3.6\t\n",
      "[ 6/50][   3008][  467.02s]\td_loss/g_loss: -1.4/-3.6\t\n",
      "[ 6/50][   3108][  481.95s]\td_loss/g_loss:  1.1/-2.6\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 36\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m critic\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[0;32m     34\u001B[0m     param\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mclamp_(\u001B[38;5;241m-\u001B[39mhp\u001B[38;5;241m.\u001B[39mweight_clip, hp\u001B[38;5;241m.\u001B[39mweight_clip)\n\u001B[1;32m---> 36\u001B[0m \u001B[43mcritic_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m critic_optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_idx \u001B[38;5;241m%\u001B[39m hp\u001B[38;5;241m.\u001B[39mn_critic \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;66;03m# Update Generator\u001B[39;00m\n",
      "File \u001B[1;32mA:\\Project\\2412\\venv\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mA:\\Project\\2412\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "img_list, generator_losses, critic_losses = [], [], []\n",
    "iters = 0\n",
    "all_labels = torch.eye(hp.num_classes, dtype=torch.float32, device=\"cuda\")\n",
    "fixed_noise = torch.randn((80, hp.latent_size), device=\"cuda\")\n",
    "fixed_class_labels = all_labels[[i for i in list(range(hp.num_classes)) for idx in range(8)]]\n",
    "grad_tensor = torch.ones((hp.batchsize, 1), device=\"cuda\")\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(hp.num_epochs):\n",
    "    for batch_idx, data in enumerate(dataloader, 0):\n",
    "        real_images, real_class_labels = data[0].to(\"cuda\"), all_labels[data[1]].to(\"cuda\")\n",
    "        \n",
    "        # Update critic\n",
    "        critic_optimizer.zero_grad()\n",
    "        \n",
    "        critic_output_real = critic(real_images, real_class_labels)\n",
    "        critic_loss_real = critic_output_real.mean()\n",
    "\n",
    "        noise = torch.randn((hp.batchsize, hp.latent_size), device=\"cuda\")\n",
    "        with torch.no_grad(): fake_image = generator(noise, real_class_labels)\n",
    "        critic_output_fake = critic(fake_image, real_class_labels)\n",
    "        critic_loss_fake = critic_output_fake.mean()\n",
    "\n",
    "        alpha = torch.rand((hp.batchsize, 1), device=\"cuda\")\n",
    "        interpolates = (alpha.view(-1, 1, 1, 1) * real_images + ((1. - alpha.view(-1, 1, 1, 1)) * fake_image)).requires_grad_(True)\n",
    "        d_interpolates = critic(interpolates, real_class_labels)\n",
    "        gradients = autograd.grad(d_interpolates, interpolates, grad_tensor, create_graph=True, only_inputs=True)[0]\n",
    "        gradient_penalty = hp.gp_lambda * ((gradients.view(hp.batchsize, -1).norm(dim=1) - 1.) ** 2).mean()\n",
    "\n",
    "        critic_loss = -critic_loss_real + critic_loss_fake  + gradient_penalty\n",
    "        run.log({\"Critic Loss\": critic_loss})\n",
    "        # weight clipping for privacy guarantee\n",
    "        for param in critic.parameters():\n",
    "            param.data.clamp_(-hp.weight_clip, hp.weight_clip)\n",
    "        \n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        if batch_idx % hp.n_critic == 0:\n",
    "            # Update Generator\n",
    "            generator_optimizer.zero_grad()\n",
    "            \n",
    "            fake_class_labels = all_labels[torch.randint(hp.num_classes, size=[hp.batchsize])]\n",
    "            noise = torch.randn((hp.batchsize, hp.latent_size), device=\"cuda\")\n",
    "            fake_image = generator(noise, fake_class_labels)\n",
    "            critic_output_fake = critic(fake_image, fake_class_labels)\n",
    "            generator_loss = -critic_output_fake.mean()\n",
    "            \n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "            run.log({\"Generator loss\": generator_loss})\n",
    "        \n",
    "        # Output training stats\n",
    "        if batch_idx % 100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"[{epoch:>2}/{hp.num_epochs}][{iters:>7}][{elapsed_time:8.2f}s]\\t\"\n",
    "                  f\"d_loss/g_loss: {critic_loss.item():4.2}/{generator_loss.item():4.2}\\t\")\n",
    "       \n",
    "        # Save Losses for plotting later\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        critic_losses.append(critic_loss.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == hp.num_epochs - 1) and (batch_idx == len(dataloader) - 1)):\n",
    "            with torch.no_grad(): \n",
    "                fake_images = generator(fixed_noise, fixed_class_labels).cpu()\n",
    "                img_list.append(vutils.make_grid(fake_images, padding=2, normalize=True))\n",
    "                run.log({\"Generated Image\": wandb.Image(vutils.make_grid(fake_images, padding=2, normalize=True))})\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), f'DPGenerator-10.pth')\n",
    "torch.save(critic.state_dict(), f'DPDiscriminator-10.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:06:54.069227300Z",
     "start_time": "2023-12-09T22:06:54.067228300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhDPdes7QYyf",
    "ExecuteTime": {
     "end_time": "2023-12-09T22:06:54.084225400Z",
     "start_time": "2023-12-09T22:06:54.069227300Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Generator and critic Loss During Training\")\n",
    "plt.plot(generator_losses,label=\"G\")\n",
    "plt.plot(critic_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX_sQ_1lTPdd",
    "ExecuteTime": {
     "start_time": "2023-12-09T22:06:54.072226600Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "##%%capture\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(i.permute(1,2,0), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "# To save the animation using Pillow as a gif\n",
    "writer = animation.PillowWriter(fps=10,\n",
    "                                metadata=dict(artist='Me'),\n",
    "                                bitrate=1800)\n",
    "ani.save('dpscatter-10.gif', writer=writer)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in img_list:\n",
    "    plt.imshow(i.permute(1,2,0))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T22:06:54.075225700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn((90, hp.latent_size), device=\"cuda\")\n",
    "fixed_class_labels = all_labels[[i for i in list(range(hp.num_classes)) for idx in range(9)]]\n",
    "with torch.no_grad(): \n",
    "    fake_images = generator(fixed_noise, fixed_class_labels).cpu()\n",
    "    i = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "    plt.imshow(i.permute(2,1,0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T22:06:54.078228800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T22:06:54.081232100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-09T22:06:54.082238600Z"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
